{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xq_I4KO4VUgHKCdxMZvHqgup9nnUfkBn","authorship_tag":"ABX9TyM3Q1gO5V4VHMJSqCOIxnGw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avzer-AY5v4p","executionInfo":{"status":"ok","timestamp":1737510859992,"user_tz":-480,"elapsed":17521,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"71fccecd-1de7-4494-cc2e-79e06cb57d23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/car-classification-api/car-classification-api\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bv1atwaCwsaP","executionInfo":{"status":"ok","timestamp":1737511619296,"user_tz":-480,"elapsed":412,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"6e1bbe5a-c064-4337-8013-8d11ec430ad6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/car-classification-api/car-classification-api\n"]}]},{"cell_type":"code","source":["!git status"],"metadata":{"id":"nu1iS9amw1E3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install torch torchvision matplotlib"],"metadata":{"id":"GEq5e_ms-i9x","executionInfo":{"status":"ok","timestamp":1737469899856,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import random_split, DataLoader, Subset\n","from sklearn.metrics import confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"0ZnCTXNb53CK","executionInfo":{"status":"ok","timestamp":1737469911768,"user_tz":-480,"elapsed":11914,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Define augmentations to be carried out\n","train_transformers = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n","    # transforms.RandomErasing(p=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transformers = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"iHE_Grf0-2hU","executionInfo":{"status":"ok","timestamp":1737470134490,"user_tz":-480,"elapsed":478,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Load the train dataset\n","train_data = datasets.ImageFolder(\"/content/drive/MyDrive/car-classification-api/data/train\")\n","\n","# Split the data further into train and val sets\n","train_size = int(0.8*len(train_data))\n","val_size = len(train_data) - train_size\n","train_indices, val_indices = random_split(range(len(train_data)), [train_size, val_size])\n","# train_dataset, val_dataset = random_split(train_data, [train_size, val_size])"],"metadata":{"id":"ZHnCWJPP57gB","executionInfo":{"status":"ok","timestamp":1737470135966,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, original_dataset, indices, transform=None):\n","        self.original_dataset = Subset(original_dataset, indices)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.original_dataset)\n","\n","    def __getitem__(self, idx):\n","        img, label = self.original_dataset[idx]\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label"],"metadata":{"id":"O9I_7PMWHhZP","executionInfo":{"status":"ok","timestamp":1737470137338,"user_tz":-480,"elapsed":273,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Define train and validation datasets with separate transforms\n","train_dataset = CustomDataset(train_data, train_indices, transform=train_transformers)\n","val_dataset = CustomDataset(train_data, val_indices, transform=val_transformers)"],"metadata":{"id":"TYCmUgBnHpAx","executionInfo":{"status":"ok","timestamp":1737470138510,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["img, label = train_dataset[3]  # Replace 0 with any valid index\n","print(type(img))  # Should show <class 'torch.Tensor'>\n","print(img.shape)  # Should show [3, 224, 224] or similar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHr9bdh3J2BJ","executionInfo":{"status":"ok","timestamp":1737470138794,"user_tz":-480,"elapsed":288,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"ec51695c-ceb1-47ae-d98f-09585b4617de"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","torch.Size([3, 224, 224])\n"]}]},{"cell_type":"code","source":["for i in range(15):  # Inspect the first 5 samples\n","  img, label = train_dataset[i]\n","  print(f\"Sample {i}: Type - {type(img)}, Shape - {img.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mexRq9Y6KTfn","executionInfo":{"status":"ok","timestamp":1737470144688,"user_tz":-480,"elapsed":4425,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"8e6b3d64-841f-4f64-ee82-46c9fb9fbcd6"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 0: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 1: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 2: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 3: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 4: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 5: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 6: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 7: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 8: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 9: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 10: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 11: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 12: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 13: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n","Sample 14: Type - <class 'torch.Tensor'>, Shape - torch.Size([3, 224, 224])\n"]}]},{"cell_type":"code","source":["# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"W6G0ZPHS6ZA0","executionInfo":{"status":"ok","timestamp":1737470146403,"user_tz":-480,"elapsed":468,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["for inputs, labels in train_loader:\n","    print(type(inputs), inputs.shape)  # Should work without error\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgZ7Z9ytKsEL","executionInfo":{"status":"ok","timestamp":1737470158714,"user_tz":-480,"elapsed":11211,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"a5f8d32e-9cc4-4ad0-b889-67475f246adc"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'> torch.Size([32, 3, 224, 224])\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"WKNvnh4RKsz0"}},{"cell_type":"code","source":["inputs, labels = next(iter(train_loader))\n","print(inputs.shape, labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PR7b0p1eJWgH","executionInfo":{"status":"ok","timestamp":1737470178988,"user_tz":-480,"elapsed":11970,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"fd16e2a2-00ed-423d-9c90-2648c4541705"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 3, 224, 224]) torch.Size([32])\n"]}]},{"cell_type":"code","source":["# Load pre-trained model, ResNet\n","model = models.resnet50(pretrained=True)\n","\n","# Modify final layer\n","num_ftrs = model.fc.in_features\n","model.fc = torch.nn.Linear(num_ftrs, len(train_data.classes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4KrKTGR-h2W","executionInfo":{"status":"ok","timestamp":1737470192238,"user_tz":-480,"elapsed":1355,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"7ec63a22-28b2-4689-9df6-21d4e54c79a8"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HwECYnJYKQZP","executionInfo":{"status":"ok","timestamp":1737470197226,"user_tz":-480,"elapsed":471,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"QugQ3TMTFhvk","executionInfo":{"status":"ok","timestamp":1737470204021,"user_tz":-480,"elapsed":517,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}},"outputId":"d621946a-abd9-40e4-8e6c-0f4f03596a3b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=196, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"metadata":{"id":"m2pKFN42A7wA","executionInfo":{"status":"ok","timestamp":1737470206409,"user_tz":-480,"elapsed":294,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","epochs = 10\n","\n","train_losses, val_losses = [], []\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        # Forward\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        # Backward\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    train_losses.append(running_loss / len(train_loader))\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0xZB5-gA9YL","outputId":"23a907aa-5c3f-46dc-8c47-d35bd83b8cdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 5.3491\n","Epoch 2/10, Loss: 5.2496\n","Epoch 3/10, Loss: 5.2057\n","Epoch 4/10, Loss: 5.1706\n"]}]},{"cell_type":"code","source":["y_true, y_pred = []\n","\n","model.eval()\n","correct = 0\n","total = 0\n","val_loss = 0.0\n","\n","with torch.no_grad():\n","    for inputs, labels in val_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","        val_loss += loss.item()\n","\n","val_losses.append(val_loss / len(val_loader))\n","print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","\n","# Convert to DataFrame for better readability\n","cm_df = pd.DataFrame(cm, index=train_data.classes, columns=train_data.classes)\n","print(cm_df)\n","\n","print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"],"metadata":{"id":"Ffr4VoTdBJ5E","executionInfo":{"status":"aborted","timestamp":1737469911770,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Val Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"6EVmV74RE1xm","executionInfo":{"status":"aborted","timestamp":1737469911770,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jasmine Ng","userId":"16998685518575972875"}}},"execution_count":null,"outputs":[]}]}