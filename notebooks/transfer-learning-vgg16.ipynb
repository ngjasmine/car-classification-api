{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning - vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This notebook explores transfer learning using the vgg16 model, where the feature extraction layers are kept frozen using the default weights and only the classifier is changed and retrained.\n",
    "- NOTE: This notebook was not run locally due to the long training time and high RAM requirements due to the number of parameters it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to sys.path if it does not exist\n",
    "project_root = Path().resolve().parents[0]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data.custom_dataset import CustomDataset\n",
    "from utils.utils import create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variant = \"mobilenet_v2\"\n",
    "timestamp = datetime.now().strftime(\"%d-%m-%Y-%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_config_path = project_root / \"conf\" / \"logger_conf.yml\"\n",
    "logs_dir = project_root / \"logs\"\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_filename = project_root / \"logs\" / f\"trnfl_{model_variant}_{timestamp}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "logger = create_logger(str(logging_config_path), str(log_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to confirm setup\n",
    "logger.info(f\"Logging initialized. Log file: {log_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentations to be carried out\n",
    "train_transformers = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    # transforms.RandomAffine(degrees=(20, 70), translate=(0.1, 0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transformers = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transformers = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = project_root / \"data\" / \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset\n",
    "train_data = ImageFolder(root=str(train_dir))\n",
    "\n",
    "# Extract labels\n",
    "labels = [train_data.targets[idx] for idx in range(len(train_data))]\n",
    "\n",
    "# Get class mapping\n",
    "class_mapping = {idx: class_name for idx, class_name in enumerate(train_data.classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split into train and val sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(train_data)), \n",
    "    test_size=0.2, \n",
    "    stratify=labels, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and validation datasets with separate transforms\n",
    "train_dataset = CustomDataset(train_data, train_indices, transform=train_transformers)\n",
    "val_dataset = CustomDataset(train_data, val_indices, transform=val_transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model, modelnet_v2\n",
    "model = models.mobilenet_v2(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify final classification layer\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, len(train_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze feature extractor (convolutional layers)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for MPS support\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use MPS (Metal Performance Shaders)\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Fallback to CUDA or CPU\n",
    "\n",
    "# Move model to the selected device\n",
    "model = model.to(device)\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training loop + eval on val\n",
    "epochs = 20\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Predictions for training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "    # Val\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Predictions for val accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print metrics \n",
    "    logger.info(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    logger.info(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Correct Predictions: {correct_train}/{total_train}\")\n",
    "    logger.info(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Correct Predictions: {correct_val}/{total_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim([min(min(train_losses), min(val_losses)) * 0.9, max(max(train_losses), max(val_losses)) * 1.1])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim([min(min(train_accuracies), min(val_accuracies)) * 0.9, 100])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = project_root / \"data\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_data = ImageFolder(str(test_dir), transform=test_transformers)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "processed_images = 0\n",
    "\n",
    "# Criterion has been defined above\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        processed_images += labels.size(0)\n",
    "        if processed_images % 500 == 0 or processed_images == total:\n",
    "            print(f\"Processed {processed_images} / {len(test_loader.dataset)} images...\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "logger.info(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "cm_df = pd.DataFrame(cm, index=test_data.classes, columns=test_data.classes)\n",
    "\n",
    "# Compute classification report\n",
    "cr = classification_report(y_true, y_pred, target_names=test_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"coolwarm\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the confusion matrix DataFrame into a long format for filtering\n",
    "cm_long = cm_df.reset_index().melt(id_vars='index', var_name='Predicted', value_name='Count')\n",
    "cm_long = cm_long.rename(columns={'index': 'Actual'})\n",
    "\n",
    "# Filter for misclassifications (Actual != Predicted) where the count is greater than 10\n",
    "misclassified = cm_long[(cm_long['Actual'] != cm_long['Predicted']) & (cm_long['Count'] > 10)]\n",
    "\n",
    "# Sort for better visibility\n",
    "misclassified = misclassified.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Display or save\n",
    "logger.info(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
